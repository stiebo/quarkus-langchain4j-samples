quarkus.langchain4j.m1.chat-model.provider=llama3-java
quarkus.langchain4j.m2.chat-model.provider=openai
quarkus.langchain4j.chat-model.provider=llama3-java

quarkus.langchain4j.llama3.m1.chat-model.model-name=mukel/Llama-3.2-1B-Instruct-GGUF
quarkus.langchain4j.llama3.m1.chat-model.quantization=Q4_0
quarkus.langchain4j.llama3.m1.chat-model.temperature=0.5
quarkus.langchain4j.llama3.m1.chat-model.pre-load-in-native=true

quarkus.langchain4j.openai.m2.api-key=${QUARKUS_LANGCHAIN4J_OPENAI_API_KEY}
quarkus.langchain4j.openai.m2.chat-model.temperature=0.5

quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true


